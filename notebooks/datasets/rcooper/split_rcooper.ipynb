{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roadvision3d.src.datasets.RCooper import RCooper\n",
    "import yaml\n",
    "\n",
    "from roadvision3d.src.datasets.kitti_utils import Object3d\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from visualizer import draw_2d_bboxes, draw_3d_bboxes\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de archivos: 53160\n",
      "Train: 41976 archivos\n",
      "Validation: 5252 archivos\n",
      "Test: 5932 archivos\n",
      "Train + Validation: 47228 archivos\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Ruta del dataset\n",
    "dataset_path = \"/home/javier/datasets/DAIR-RCooper/data\"\n",
    "split_ratios = [0.8, 0.1, 0.1]\n",
    "\n",
    "# Definir las intersecciones y cámaras en un diccionario\n",
    "intersections = {\n",
    "    \"106-105\": [\"105\", \"106\"],\n",
    "    \"116-115\": [\"116\", \"115\"],\n",
    "    \"117-118-120-119\": [\"117\", \"118\", \"119\", \"120\"],\n",
    "    \"136-137-138-139\": [\"136\", \"137\", \"138\", \"139\"],\n",
    "}\n",
    "\n",
    "# Función para hacer el split de una lista de secuencias\n",
    "def split_data(data, ratios):\n",
    "    random.shuffle(data)\n",
    "    train_size = int(len(data) * ratios[0])\n",
    "    val_size = int(len(data) * ratios[1])\n",
    "    \n",
    "    train_data = data[:train_size]\n",
    "    val_data = data[train_size:train_size + val_size]\n",
    "    test_data = data[train_size + val_size:]\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Función principal para generar los archivos de split con splits iguales para cámaras de la misma intersección\n",
    "def generate_split_files(dataset_path, intersections, split_ratios):\n",
    "    # Archivos de salida\n",
    "    train_file = open(\"train.txt\", \"w\")\n",
    "    val_file = open(\"val.txt\", \"w\")\n",
    "    test_file = open(\"test.txt\", \"w\")\n",
    "    train_val_file = open(\"train_val.txt\", \"w\")  # Archivo adicional para train + val\n",
    "    \n",
    "    # Contadores para cada split\n",
    "    train_count = 0\n",
    "    val_count = 0\n",
    "    test_count = 0\n",
    "    train_val_count = 0\n",
    "    \n",
    "    for intersection, cameras in intersections.items():\n",
    "        # Obtener todas las secuencias en la intersección, considerando ambas cámaras\n",
    "        all_sequences = []\n",
    "        for camera in cameras:\n",
    "            camera_path = os.path.join(dataset_path, intersection, camera)\n",
    "            if os.path.exists(camera_path):\n",
    "                sequences = [seq for seq in os.listdir(camera_path) if os.path.isdir(os.path.join(camera_path, seq))]\n",
    "                all_sequences.extend([(camera, seq) for seq in sequences])\n",
    "\n",
    "        # Filtrar duplicados y realizar el split en secuencias\n",
    "        unique_sequences = list(set(seq for _, seq in all_sequences))  # Obtener secuencias únicas\n",
    "        train_seqs, val_seqs, test_seqs = split_data(unique_sequences, split_ratios)\n",
    "        \n",
    "        # Función para escribir las rutas de imágenes completas en el archivo correspondiente\n",
    "        def write_image_paths(file, intersection, camera, seq):\n",
    "            nonlocal train_count, val_count, test_count, train_val_count\n",
    "            seq_path = os.path.join(dataset_path, intersection, camera, seq)\n",
    "            for cam_dir in os.listdir(seq_path):\n",
    "                cam_path = os.path.join(seq_path, cam_dir)\n",
    "                if os.path.isdir(cam_path):  # Asegurarse de que sea un directorio\n",
    "                    # Listar imágenes en orden para mantener la secuencia\n",
    "                    img_files = sorted(f for f in os.listdir(cam_path) if f.endswith(\".jpg\"))\n",
    "                    for img_file in img_files:\n",
    "                        img_path = os.path.join(intersection, camera, seq, cam_dir, img_file)\n",
    "                        file.write(f\"{img_path[:-4]}\\n\")  # Escribir sin la extensión .jpg\n",
    "                        if file == train_file:\n",
    "                            train_count += 1\n",
    "                        elif file == val_file:\n",
    "                            val_count += 1\n",
    "                        elif file == test_file:\n",
    "                            test_count += 1\n",
    "                        if file in (train_file, val_file):\n",
    "                            train_val_count += 1\n",
    "        \n",
    "        # Escribir en los archivos el mismo split para ambas cámaras\n",
    "        for camera in cameras:\n",
    "            for seq in train_seqs:\n",
    "                write_image_paths(train_file, intersection, camera, seq)\n",
    "                write_image_paths(train_val_file, intersection, camera, seq)  # También en train_val\n",
    "            for seq in val_seqs:\n",
    "                write_image_paths(val_file, intersection, camera, seq)\n",
    "                write_image_paths(train_val_file, intersection, camera, seq)  # También en train_val\n",
    "            for seq in test_seqs:\n",
    "                write_image_paths(test_file, intersection, camera, seq)\n",
    "    \n",
    "    # Cerrar los archivos\n",
    "    train_file.close()\n",
    "    val_file.close()\n",
    "    test_file.close()\n",
    "    train_val_file.close()\n",
    "    \n",
    "    # Imprimir los contadores\n",
    "    total_count = train_count + val_count + test_count\n",
    "    print(f\"Total de archivos: {total_count}\")\n",
    "    print(f\"Train: {train_count} archivos\")\n",
    "    print(f\"Validation: {val_count} archivos\")\n",
    "    print(f\"Test: {test_count} archivos\")\n",
    "    print(f\"Train + Validation: {train_val_count} archivos\")\n",
    "\n",
    "# Llamada a la función\n",
    "generate_split_files(dataset_path, intersections, split_ratios)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split DAIR format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split summary:\n",
      "Total images: 26580\n",
      "Train: 21264\n",
      "Validation: 2658\n",
      "Train+Validation: 23922\n",
      "Test: 2658\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Function to collect images by directory hierarchy\n",
    "def collect_images(root_path):\n",
    "    relative_image_paths = []\n",
    "    \n",
    "    for main_dir in [\"corridor\", \"intersection\"]:\n",
    "        main_dir_path = os.path.join(root_path, main_dir)\n",
    "        if not os.path.isdir(main_dir_path):\n",
    "            continue\n",
    "        \n",
    "        for pov in [\"vehicle-side\", \"infrastructure-side\"]:\n",
    "            pov_dir_path = os.path.join(main_dir_path, pov, \"image\")\n",
    "            if not os.path.isdir(pov_dir_path):\n",
    "                continue\n",
    "            \n",
    "            for file in os.listdir(pov_dir_path):\n",
    "                if file.endswith(\".jpg\"):\n",
    "                    relative_path = os.path.join(main_dir, pov, \"image\", file)\n",
    "                    relative_image_paths.append(relative_path)\n",
    "    \n",
    "    return relative_image_paths\n",
    "\n",
    "# Function to split the dataset\n",
    "def split_dataset(image_paths, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    random.shuffle(image_paths)  # Shuffle for randomness\n",
    "    total_images = len(image_paths)\n",
    "    \n",
    "    train_count = int(total_images * train_ratio)\n",
    "    val_count = int(total_images * val_ratio)\n",
    "    \n",
    "    train_images = image_paths[:train_count]\n",
    "    val_images = image_paths[train_count:train_count + val_count]\n",
    "    test_images = image_paths[train_count + val_count:]\n",
    "    \n",
    "    return train_images, val_images, train_images + val_images, test_images\n",
    "\n",
    "# Function to save splits to .txt files\n",
    "def save_splits(output_dir, train, val, trainval, test):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    def remove_extension_and_sort(paths):\n",
    "        return sorted([os.path.splitext(path)[0] for path in paths])  # Sort alphabetically\n",
    "    \n",
    "    with open(os.path.join(output_dir, \"train.txt\"), \"w\") as f:\n",
    "        f.writelines(f\"{line}\\n\" for line in remove_extension_and_sort(train))\n",
    "    with open(os.path.join(output_dir, \"val.txt\"), \"w\") as f:\n",
    "        f.writelines(f\"{line}\\n\" for line in remove_extension_and_sort(val))\n",
    "    with open(os.path.join(output_dir, \"trainval.txt\"), \"w\") as f:\n",
    "        f.writelines(f\"{line}\\n\" for line in remove_extension_and_sort(trainval))\n",
    "    with open(os.path.join(output_dir, \"test.txt\"), \"w\") as f:\n",
    "        f.writelines(f\"{line}\\n\" for line in remove_extension_and_sort(test))\n",
    "\n",
    "# Main logic\n",
    "dataset_root = \"/home/javier/datasets/DAIR-RCooper/RCooper-DAIR\"\n",
    "output_dir = \"/home/javier/datasets/DAIR-RCooper/RCooper-DAIR\"\n",
    "\n",
    "image_paths = collect_images(dataset_root)\n",
    "train, val, trainval, test = split_dataset(image_paths)\n",
    "save_splits(output_dir, train, val, trainval, test)\n",
    "\n",
    "# Print summary of the splits\n",
    "print(\"Dataset split summary:\")\n",
    "print(f\"Total images: {len(image_paths)}\")\n",
    "print(f\"Train: {len(train)}\")\n",
    "print(f\"Validation: {len(val)}\")\n",
    "print(f\"Train+Validation: {len(trainval)}\")\n",
    "print(f\"Test: {len(test)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
